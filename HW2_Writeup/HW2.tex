\documentclass{article}

\usepackage{fancyhdr}
\usepackage{extramarks}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{tikz}
\usepackage[plain]{algorithm}
\usepackage{algpseudocode}

\usetikzlibrary{automata,positioning}

%
% Basic Document Settings
%

\topmargin=-0.45in
\evensidemargin=0in
\oddsidemargin=0in
\textwidth=6.5in
\textheight=9.0in
\headsep=0.25in

\linespread{1.1}

\pagestyle{fancy}
\rhead{\firstxmark}
\lfoot{\lastxmark}
\cfoot{\thepage}

\renewcommand\headrulewidth{0.4pt}
\renewcommand\footrulewidth{0.4pt}

\setlength\parindent{0pt}

%
% Create Problem Sections
%

\newcommand{\enterProblemHeader}[1]{
    \nobreak\extramarks{}{Problem \arabic{#1} continued on next page\ldots}\nobreak{}
    \nobreak\extramarks{Problem \arabic{#1} (continued)}{Problem \arabic{#1} continued on next page\ldots}\nobreak{}
}

\newcommand{\exitProblemHeader}[1]{
    \nobreak\extramarks{Problem \arabic{#1} (continued)}{Problem \arabic{#1} continued on next page\ldots}\nobreak{}
    \stepcounter{#1}
    \nobreak\extramarks{Problem \arabic{#1}}{}\nobreak{}
}

\setcounter{secnumdepth}{0}
\newcounter{partCounter}
\newcounter{homeworkProblemCounter}
\setcounter{homeworkProblemCounter}{1}
\nobreak\extramarks{Problem \arabic{homeworkProblemCounter}}{}\nobreak{}

%
% Homework Problem Environment
%
% This environment takes an optional argument. When given, it will adjust the
% problem counter. This is useful for when the problems given for your
% assignment aren't sequential. See the last 3 problems of this template for an
% example.
%
\newenvironment{homeworkProblem}[1][-1]{
    \ifnum#1>0
        \setcounter{homeworkProblemCounter}{#1}
    \fi
    \section{Problem \arabic{homeworkProblemCounter}}
    \setcounter{partCounter}{1}
    \enterProblemHeader{homeworkProblemCounter}
}{
    \exitProblemHeader{homeworkProblemCounter}
}



%
% Homework Details
%   - Title
%   - Due date
%   - Class
%   - Section/Time
%   - Instructor
%   - Author
%

\newcommand{\hmwkTitle}{Homework\ \#2}
\newcommand{\hmwkName}{Search Problems in AI}
\newcommand{\hmwkDate}{March 10, 2023}
\newcommand{\hmwkClass}{CS 440: Introduction to Artificial Intelligence}
\newcommand{\hmwkClassInstructor}{Professor Abdelsam Boularias}


%
% Title Page
%

\title{
    \vspace{2in}
    \textmd{\textbf{\hmwkClass}}\\
    \textmd{\hmwkTitle\ \hmwkName}\\
    \vspace{0.1in}\small{\hmwkDate}\\
    \vspace{0.1in}\large{\textit{\hmwkClassInstructor}}
    \vspace{3in}
}

\author{
    \textbf{Jay Patwardhan} {208001851}\\ 
    \textbf{Alan Wu} {208000574}\\ 
    \textbf{Neel Shejwalkar} {207004853}
}
\date{}

\renewcommand{\part}[1]{\textbf{\large Part \Alph{partCounter}}\stepcounter{partCounter}\\}

%
% Various Helper Commands
%

% Useful for algorithms
\newcommand{\alg}[1]{\textsc{\bfseries \footnotesize #1}}

% For derivatives
\newcommand{\deriv}[1]{\frac{\mathrm{d}}{\mathrm{d}x} (#1)}

% For partial derivatives
\newcommand{\pderiv}[2]{\frac{\partial}{\partial #1} (#2)}

% Integral dx
\newcommand{\dx}{\mathrm{d}x}

% Alias for the Solution section header
\newcommand{\bruh}{\textbf{\large Solution}}
\newtheorem*{solution*}{Solution}
\newenvironment{solution}{\begin{solution*}}{{\finishline} \end{solution*}}


% Probability commands: Expectation, Variance, Covariance, Bias
\newcommand{\E}{\mathrm{E}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\Bias}{\mathrm{Bias}}

\begin{document}

\maketitle

\pagebreak

%Part 1%
\begin{homeworkProblem}
    \textbf{\large Tracing Operation $A^{*}$ from Lugoj to Bucharest}\\\\
    By applying the $A^{*}$ tree search algorithm on the graph using the straight line distance heuristic, we end up with the following sequence of nodes expanded in order, written in tuples in the form described in the assignment:
    \begin{align}
        (Lugoj, 244, 0, 244) \\
        (Mehadia, 311, 70, 241) \\
        (Lugoj, 384, 140, 244) \\
        (Drobeta, 387, 145, 242) \\
        (Craiova, 425, 265, 160) \\
        (Timisoara, 440, 111, 329) \\
        (Mehadia, 451, 210, 241) \\
        (Mehadia, 461, 220, 241) \\
        (Lugoj, 466, 222, 244) \\
        (Pitesti, 503, 403, 100) \\
        (Bucharest, 504, 504, 0)
    \end{align}

\end{homeworkProblem}

\pagebreak

%Part 2%
\begin{homeworkProblem}
    \textbf{\large Consider a state space where the start state is number 1 and each state $k$ has two successors: numbers $2k$ and $2k + 1$.}\\\\
    \part

    \textbf{\large Suppose the goal state is 11. List the order in which states will be visited for breadthfirst search, depth-limited search
    with limit 3, and iterative deepening search.}

    \begin{solution*}
        The list of states visited for each search algorithm is as follows: \\
        For Breadth-First Search: $(1,2,3,4,5,6,7,8,9,10,11)$ \\
        For Depth-Limited Search, limit 3: $(1,2,4,8,9,5,10,11)$ \\
        For Iterative Deepening search:
        \begin{align*}
            &Limit = 0   &(1) \\
            &Limit = 1   &(1,2,3) \\
            &Limit = 2   &(1,2,4,5,3,6,7) \\
            &Limit = 3   &(1,2,4,8,9,5,10,11) \\
        \end{align*}

    \end{solution*}

    \part

    \textbf{\large How well would bidirectional search work on this problem? List the order in which states will be visited. What is the
    branching factor in each direction of the bidirectional search?}

    \begin{solution*}
        The branching factor from the direction of the root node is 2, as every node has 2 children, and every parent node would have already been searched.
        The branching factor from the direction of the goal node is 3, as we have to account for its 2 children as well as the parent node. \\
        Asymptotically, bidirectional search is better than the other singular directional algorithms above (on the order of $O(2^{d/2}+3^{d/2})$ versus $O(2^{d})$)
        but when d is a small value like in this problem, it is possible for it to not perform as well. \\
        The explored states are: $(1,11,2,3,5,22,23,4,5)$.
    \end{solution*}


   
\end{homeworkProblem}

\pagebreak

%Part 2%
\begin{homeworkProblem}
    \textbf{\large Correct vs. Not Correct}\\\\

    \part  
    
    \large Breadth-first search is a special case of uniform-cost search.\\\\

    \part
    
    \large Depth-first search is a special case of best-first tree search.\\\\

    \part
    
    \large Uniform-cost search is a special case of $A^{*}$ search.\\\\


    \part
    \large Depth-first graph search is guaranteed to return an optimal solution\\\\

    \part
    \large Breadth-first graph search is guaranteed to return an optimal solution.\\\\

    \part
    \large Uniform-cost graph search is guaranteed to return an optimal solution.\\\\

    \part
    \large $A^{*}$ graph search is guaranteed to return an optimal solution if the heuristic is consistent.\\\\

    \part
    \large $A^{*}$ graph search is guaranteed to expand no more nodes than depth-first graph search if the heuristic is consistent.\\\\

    \part 
    \large $A^{*}$ graph search is guaranteed to expand no more nodes than uniform-cost graph search if the heuristic is consistent.\\\\


   
\end{homeworkProblem}

\pagebreak

%Part 4%
\begin{homeworkProblem}
    \textbf{\large Iterative deepening is sometimes used as an alternative to breadth first search. Give one advantage
    of iterative deepening over BFS, and give one disadvantage of iterative deepening as compared with BFS. Be concise and
    specific.}\\\\
    An advantage that IDS has over BFS is its efficient use of space. BFS uses $O(b^d)$ space as it must store at worst every single node in the tree of a depth shallower than the goal node.
    In comparison, IDS is identical to Depth-First search during each one of its iterations. This means that IDS has a space complexity of $O(bd)$ or even $O(d)$ depending on the implementation, far better than the exponential space required for BFS. \\\\
    IDS has the disadvantage of being much less efficient with time than BFS. While they are both similar asymptotically, with a complexity of $O(b^d)$, IDS needs to search a tree of depth $i$ for every single iteration $0\leq i\leq d$, whereas BFS needs to only search the tree of depth d once before finding the goal node. 
    This means the runtime of IDS has a looser upper bound of $O(b^d + b^{d-1} + \ldots + b + 1)$, which is far more expensive practically.

\end{homeworkProblem}

\pagebreak

%Part 5
\begin{homeworkProblem}
    \textbf{\large Prove that if a heuristic is consistent, then it must be admissible. Construct an example of an admissible heuristic that is not consistent. (Hint: You can draw a small graph of 3 nodes and write arbitrary cost and heuristic values so that the heuristic is admissible but not consistent.)}\\\\
    We will prove this claim using induction over all nodes. \\
    Base case: Let $n_0$ be the goal node, and $n_1$ be a node one step away. By the definition of a consistent heuristic,
    \begin{align*}
        h(n_1) &\leq c(n_1, a, n_0) + h(n_0) \\
        h(n_1) &\leq c(n_1, a, n_0) + 0 \\
        h(n_1) &\leq h^{*}(n_1)
    \end{align*}
    as the heuristic is defined to be 0 at the goal node, and the cost of the path from $n_1$ to $n_0$ is exactly the true cost of the path to the goal, $h^{*}(n_1)$.
    So, h demonstrates admissible behavior for the base case. \\
    Inductive hypothesis: Let the condition $h(n_k) \leq h^{*}(n_k)$ hold for some node $n_k$ that is $k$ steps away from the goal node. \\
    Inductive step: We'll now look at a node $n_{k+1}$ that is $k+1$ steps away from the goal node. By the definition of consistency,
    \begin{align*}
        h(n_{k+1}) &\leq c(n_{k+1}, a, n_k) + h(n_k) \\
    \end{align*}
    By the inductive hypothesis, 
    \begin{align*}
        h(n_{k+1}) &\leq c(n_{k+1}, a, n_k) + h^{*}(n_k) \\
    \end{align*}
    Now notice that $c(n_{k+1}, a, n_k) + h^{*}(n_k)$ is exactly the true distance from the node $n_{k+1}$. So, then
    \begin{align*}
        h(n_{k+1}) &\leq h^{*}(n_{k+1}) \\
    \end{align*}
    And so the heuristic is admissible for all nodes. \qed

    
\end{homeworkProblem}

\pagebreak

%Part 6
\begin{homeworkProblem}
    \textbf{\large In a Constraint Satisfaction Problem search, explain why it is a good heuristic to choose the variable that is most constrained but the value that is least constraining.}\\\\

    
\end{homeworkProblem}
\pagebreak
%Part 7%
\begin{homeworkProblem}
    \textbf{\large Consider the following game tree, where the first move is made by the MAX player and the second move is made by the MIN player.}\\\\

   
    \part 

    \textbf{\large What is the best move for the MAX player using the minimax procedure?}\\\\
        The MAX player here has two moves, to go to state B (we'll call this action $a_1$) or go to state C ($a_2$). 
        If MAX chooses $a_1$, then MAX will end with a utility of 3. If MAX choose $a_2$, it ends with a utility of 4 as the game progresses towards state H. 
        We can check this result directly using the definition of the MINIMAX function:
        \begin{align*}
            MINIMAX(root) &= max(min(3,5), min(max(min(0,7), 5), max(7,8), 4)) \\
            &= max(3, min(5,8,4)) \\
            &= max(3,4) = 4
        \end{align*} \\
    \part 

    \textbf{\large Perform a left-to-right (left branch first, then right branch) alpha-beta pruning on the tree. That is, draw only the parts of the tree that are visited and don't draw branches that are cut off (no need to show the alpha or beta values).}\\\\
        \includegraphics*[scale=0.2]{lefttoright.png} \\\\


    \part 

    \textbf{\large Do the same thing as in the previous question, but with a right-to-left ordering of the actions. Discuss why different pruning occurs.} \\\\
        \includegraphics*[scale=0.2]{righttoleft.png} \\
    The differences in pruning arise because we are visiting the nodes in a different order. When going from left to right, the left node is checked with other states
    to see if pruning is a possibility, and if so, the right subtree is pruned. Conversely, going from right to left means that the right node is checked first and left subtrees are pruned.
    This difference in order is what changes the result. For example, when pruning left to right, we visited node K before node L. Seeing as the utility of node K was 7, we pruned off the right subtree of G 
    (as the MIN player would rather go to node F regardless of what node K was). Similarly, when going from right to left, the left subtree of G was pruned (as the MIN player would have opted for node H). 


\end{homeworkProblem}
\pagebreak 

%Part 8%
\begin{homeworkProblem}
\textbf{\large Which of the following are admissible, given admissible heuristics $h_1, h_2$? Which of the following
are consistent, given consistent heuristics $h_1, h_2$? Justify your ans}

\part 

\large $h(n) = min(h_1(n), h_2(n))$\\\\

\part 

\large $h(n) = \omega h_1(n) + (1-\omega)h_2(n)$, where $0 \le \omega \le 1$.\\\\


\part

\large $h(n) = max(h_1(n), h_2(n))$\\\\

\end{homeworkProblem}
\pagebreak
%Part 9%
\begin{homeworkProblem}
    \textbf{\large Simulated annealing is an extension of hill climbing, which uses randomness to avoid getting stuck
    in local maxima and plateaux.}

    \part 
    \large For what types of problems will hill climbing work better than simulated annealing? In other words, when is the
    random part of simulated annealing not necessary?\\\\
    

    \part 

    \large For what types of problems will randomly guessing the state work just as well as simulated annealing? In other
    words, when is the hill-climbing part of simulated annealing not necessary?\\\\


    \part 

    \large Reasoning from your answers to parts (a) and (b) above, for what types of problems is simulated annealing a useful
    technique? In other terms, what assumptions about the shape of the value function are implicit in the design of
    simulated annealing?\\\\

    \part 

    \large As defined in your textbook, simulated annealing returns the current state when the end of the annealing schedule is
    reached and if the annealing schedule is slow enough. Given that we know the value (measure of goodness) of each
    state we visit, is there anything smarter we could do?\\\\

    \part 

    \large Simulated annealing requires a very small amount of memory, just enough to store two states: the current state and
    the proposed next state. Suppose we had enough memory to hold two million states. Propose a modification to
    simulated annealing that makes productive use of the additional memory. In particular, suggest something that will
    likely perform better than just running simulated annealing a million times consecutively with random restarts. [Note:
    There are multiple correct answers here.]\\\\
    
    \part
    
    \large Gradient ascent search is prone to local optima just like hill climbing. Describe how you might adapt randomness in
    simulated annealing to gradient ascent search avoid trap of local maximum.\\\\

    
\end{homeworkProblem}



\end{document}