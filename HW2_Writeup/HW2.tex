\documentclass{article}

\usepackage{fancyhdr}
\usepackage{extramarks}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{tikz}
\usepackage[plain]{algorithm}
\usepackage{algpseudocode}

\usetikzlibrary{automata,positioning}

%
% Basic Document Settings
%

\topmargin=-0.45in
\evensidemargin=0in
\oddsidemargin=0in
\textwidth=6.5in
\textheight=9.0in
\headsep=0.25in

\linespread{1.1}

\pagestyle{fancy}
\rhead{\firstxmark}
\lfoot{\lastxmark}
\cfoot{\thepage}

\renewcommand\headrulewidth{0.4pt}
\renewcommand\footrulewidth{0.4pt}

\setlength\parindent{0pt}

%
% Create Problem Sections
%

\newcommand{\enterProblemHeader}[1]{
    \nobreak\extramarks{}{Problem \arabic{#1} continued on next page\ldots}\nobreak{}
    \nobreak\extramarks{Problem \arabic{#1} (continued)}{Problem \arabic{#1} continued on next page\ldots}\nobreak{}
}

\newcommand{\exitProblemHeader}[1]{
    \nobreak\extramarks{Problem \arabic{#1} (continued)}{Problem \arabic{#1} continued on next page\ldots}\nobreak{}
    \stepcounter{#1}
    \nobreak\extramarks{Problem \arabic{#1}}{}\nobreak{}
}

\setcounter{secnumdepth}{0}
\newcounter{partCounter}
\newcounter{homeworkProblemCounter}
\setcounter{homeworkProblemCounter}{1}
\nobreak\extramarks{Problem \arabic{homeworkProblemCounter}}{}\nobreak{}

%
% Homework Problem Environment
%
% This environment takes an optional argument. When given, it will adjust the
% problem counter. This is useful for when the problems given for your
% assignment aren't sequential. See the last 3 problems of this template for an
% example.
%
\newenvironment{homeworkProblem}[1][-1]{
    \ifnum#1>0
        \setcounter{homeworkProblemCounter}{#1}
    \fi
    \section{Problem \arabic{homeworkProblemCounter}}
    \setcounter{partCounter}{1}
    \enterProblemHeader{homeworkProblemCounter}
}{
    \exitProblemHeader{homeworkProblemCounter}
}



%
% Homework Details
%   - Title
%   - Due date
%   - Class
%   - Section/Time
%   - Instructor
%   - Author
%

\newcommand{\hmwkTitle}{Homework\ \#2}
\newcommand{\hmwkName}{Search Problems in AI}
\newcommand{\hmwkDate}{March 10, 2023}
\newcommand{\hmwkClass}{CS 440: Introduction to Artificial Intelligence}
\newcommand{\hmwkClassInstructor}{Professor Abdelsam Boularias}


%
% Title Page
%

\title{
    \vspace{2in}
    \textmd{\textbf{\hmwkClass}}\\
    \textmd{\hmwkTitle\ \hmwkName}\\
    \vspace{0.1in}\small{\hmwkDate}\\
    \vspace{0.1in}\large{\textit{\hmwkClassInstructor}}
    \vspace{3in}
}

\author{
    \textbf{Jay Patwardhan} {208001851}\\ 
    \textbf{Alan Wu} {208000574}\\ 
    \textbf{Neel Shejwalkar} {207004853}
}
\date{}

\renewcommand{\part}[1]{\textbf{\large Part \Alph{partCounter}}\stepcounter{partCounter}\\}

%
% Various Helper Commands
%

% Useful for algorithms
\newcommand{\alg}[1]{\textsc{\bfseries \footnotesize #1}}

% For derivatives
\newcommand{\deriv}[1]{\frac{\mathrm{d}}{\mathrm{d}x} (#1)}

% For partial derivatives
\newcommand{\pderiv}[2]{\frac{\partial}{\partial #1} (#2)}

% Integral dx
\newcommand{\dx}{\mathrm{d}x}

% Alias for the Solution section header
\newcommand{\bruh}{\textbf{\large Solution}}
\newtheorem*{solution*}{Solution}
\newenvironment{solution}{\begin{solution*}}{{\finishline} \end{solution*}}


% Probability commands: Expectation, Variance, Covariance, Bias
\newcommand{\E}{\mathrm{E}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\Bias}{\mathrm{Bias}}

\begin{document}

\maketitle

\pagebreak

%Part 1%
\begin{homeworkProblem}
    \textbf{\large Tracing Operation $A^{*}$ from Lugoj to Bucharest}\\\\
    By applying the $A^{*}$ tree search algorithm on the graph using the straight line distance heuristic, we end up with the following sequence of nodes expanded in order, written in tuples in the form described in the assignment:
    \begin{align}
        (Lugoj, 244, 0, 244) \\
        (Mehadia, 311, 70, 241) \\
        (Lugoj, 384, 140, 244) \\
        (Drobeta, 387, 145, 242) \\
        (Craiova, 425, 265, 160) \\
        (Timisoara, 440, 111, 329) \\
        (Mehadia, 451, 210, 241) \\
        (Mehadia, 461, 220, 241) \\
        (Lugoj, 466, 222, 244) \\
        (Pitesti, 503, 403, 100) \\
        (Bucharest, 504, 504, 0)
    \end{align}

\end{homeworkProblem}

\pagebreak

%Part 2%
\begin{homeworkProblem}
    \textbf{\large Consider a state space where the start state is number 1 and each state $k$ has two successors: numbers $2k$ and $2k + 1$.}\\\\
    \part

    \textbf{\large Suppose the goal state is 11. List the order in which states will be visited for breadthfirst search, depth-limited search
    with limit 3, and iterative deepening search.}

    \begin{solution*}
        The list of states visited for each search algorithm is as follows: \\
        For Breadth-First Search: $(1,2,3,4,5,6,7,8,9,10,11)$ \\
        For Depth-Limited Search, limit 3: $(1,2,4,8,9,5,10,11)$ \\
        For Iterative Deepening search:
        \begin{align*}
            &Limit = 0   &(1) \\
            &Limit = 1   &(1,2,3) \\
            &Limit = 2   &(1,2,4,5,3,6,7) \\
            &Limit = 3   &(1,2,4,8,9,5,10,11) \\
        \end{align*}

    \end{solution*}

    \part

    \textbf{\large How well would bidirectional search work on this problem? List the order in which states will be visited. What is the
    branching factor in each direction of the bidirectional search?}

    \begin{solution*}
        The branching factor from the direction of the root node is 2, as every node has 2 children, and every parent node would have already been searched.
        The branching factor from the direction of the goal node is 3, as we have to account for its 2 children as well as the parent node. \\
        Asymptotically, bidirectional search is better than the other singular directional algorithms above (on the order of $O(2^{d/2}+3^{d/2})$ versus $O(2^{d})$)
        but when d is a small value like in this problem, it is possible for it to not perform as well. \\
        The explored states are: $(1,11,2,3,5,22,23,4,5)$.
    \end{solution*}


   
\end{homeworkProblem}

\pagebreak

%Part 2%
\begin{homeworkProblem}
    \textbf{\large Correct vs. Not Correct}\\\\

    \part  
    
    \large True: Breadth-first search is a special case of uniform-cost search, if we set the cost function c(s,s') = 1 for all states s and s'.\\\\

    \part
    
    \large True: Depth-first search is a special case of best-first tree search with $f(n) := 1/depth(n)$\\\\

    \part
    
    \large True: Uniform-cost search is a special case of $A^{*}$ search with h(s) = 0 for all states s.\\\\


    \part
    \large False: Depth-first graph search is NOT guaranteed to return an optimal solution, as it could go down directly to a sub-optimal solution simply because it's the first and longest path.\\\\

    \part
    \large False: Breadth-first graph search is NOT guaranteed to return an optimal solution unless all actions have the same cost, as it could find a very expensive but short path to a solution state (think root $\xrightarrow{}$ solution but the cost is 500, but there is another path root $\xrightarrow{}$ intermediary $\xrightarrow{}$ solution whose costs for both actions are 1).\\\\

    \part
    \large True: Uniform-cost graph search is guaranteed to return an optimal solution, as it expands nodes based on smallest cost, so the solution it finds is optimal.\\\\

    \part
    \large True: $A^{*}$ graph search is guaranteed to return an optimal solution if the heuristic is consistent, since by theorems in the slides consistent heuristics are optimal (slide 17 on the A* lecture slides).\\\\

    \part
    \large False: $A^{*}$ graph search is NOT guaranteed to expand no more nodes than depth-first graph search if the heuristic is consistent, since DFS can go immediately to a sub-optimal solution in its first run down, while A* will take a long time expanding many nodes and determine the most optimal solution.\\\\

    \part 
    \large True: $A^{*}$ graph search is guaranteed to expand no more nodes than uniform-cost graph search if the heuristic is consistent, since the heuristic makes the search more informed. We use that UCS is a special case of A* with $h(n) = 0$ for all n. Since h as the estimated shortest cost is necessarily nonnegative, it follows that $f(n) = g(n) + h(n) >= g(n) + 0$ for all n, and thus if we have two heuristics: 0 and h(n), we have a more informed heuristic h(n), which by definition will expand no more nodes than the less informed heuristic 0. \\\\


   
\end{homeworkProblem}

\pagebreak

%Part 4%
\begin{homeworkProblem}
    \textbf{\large Iterative deepening is sometimes used as an alternative to breadth first search. Give one advantage
    of iterative deepening over BFS, and give one disadvantage of iterative deepening as compared with BFS. Be concise and
    specific.}\\\\
    An advantage that IDS has over BFS is its efficient use of space. BFS uses $O(b^d)$ space as it must store at worst every single node in the tree of a depth shallower than the goal node.
    In comparison, IDS is identical to Depth-First search during each one of its iterations. This means that IDS has a space complexity of $O(bd)$ or even $O(d)$ depending on the implementation, far better than the exponential space required for BFS. \\\\
    IDS has the disadvantage of being much less efficient with time than BFS. While they are both similar asymptotically, with a complexity of $O(b^d)$, IDS needs to search a tree of depth $i$ for every single iteration $0\leq i\leq d$, whereas BFS needs to only search the tree of depth d once before finding the goal node. 
    This means the runtime of IDS has a looser upper bound of $O(b^d + b^{d-1} + \ldots + b + 1)$, which is far more expensive practically.

\end{homeworkProblem}

\pagebreak

%Part 5
\begin{homeworkProblem}
    \textbf{\large Prove that if a heuristic is consistent, then it must be admissible. Construct an example of an admissible heuristic that is not consistent. (Hint: You can draw a small graph of 3 nodes and write arbitrary cost and heuristic values so that the heuristic is admissible but not consistent.)}\\\\
    We will prove this claim using induction over all nodes. \\
    Base case: Let $n_0$ be the goal node, and $n_1$ be a node one step away. By the definition of a consistent heuristic,
    \begin{align*}
        h(n_1) &\leq c(n_1, a, n_0) + h(n_0) \\
        h(n_1) &\leq c(n_1, a, n_0) + 0 \\
        h(n_1) &\leq h^{*}(n_1)
    \end{align*}
    as the heuristic is defined to be 0 at the goal node, and the cost of the path from $n_1$ to $n_0$ is exactly the true cost of the path to the goal, $h^{*}(n_1)$.
    So, h demonstrates admissible behavior for the base case. \\
    Inductive hypothesis: Let the condition $h(n_k) \leq h^{*}(n_k)$ hold for some node $n_k$ that is $k$ steps away from the goal node. \\
    Inductive step: We'll now look at a node $n_{k+1}$ that is $k+1$ steps away from the goal node. By the definition of consistency,
    \begin{align*}
        h(n_{k+1}) &\leq c(n_{k+1}, a, n_k) + h(n_k) \\
    \end{align*}
    By the inductive hypothesis, 
    \begin{align*}
        h(n_{k+1}) &\leq c(n_{k+1}, a, n_k) + h^{*}(n_k) \\
    \end{align*}
    Now notice that $c(n_{k+1}, a, n_k) + h^{*}(n_k)$ is exactly the true distance from the node $n_{k+1}$. So, then
    \begin{align*}
        h(n_{k+1}) &\leq h^{*}(n_{k+1}) \\
    \end{align*}
    And so the heuristic is admissible for all nodes. \qed

    
\end{homeworkProblem}

\pagebreak

%Part 6
\begin{homeworkProblem}
    \textbf{\large In a Constraint Satisfaction Problem search, explain why it is a good heuristic to choose the variable that is most constrained but the value that is least constraining.}\\\\
    Choosing a fail first/most constrained variable is a good heuristic because it allows us to quickly prune that branch of the search tree, letting us avoid pointless searches through other variables. In other words, if a variable has a lot of constraints, then it will likely have very few outcomes, if there even exist any at all which satisfy the constraints it has as well as the previous constraints which led to this point of the tree. Since it the most selective, it would be good to satisfy its constraints earlier rather than later down the tree. If we selected a less restrictive variable first, it could lead to many more branches, each of which will eventually settle upon this particular constraint, and most branches will terminate there because they don't satisfy such restrictive constraints. However, this takes up a lot of extra time (to compute down the tree) and space (to store each branch of the tree), and so it is best to consider the most restrictive variables first, because they will avoid these useless terminating searches where they are not necessary.\\\\
    Next, it would be best to consider the least constraining value for the variable. The only way to fail is to test all the values, so there is no reason to attempt fail first strategies in which we purposefully test values that will result in failure first. In this moment, it is best to select a value which will allow the largest range of potential variables stemming from it, because there is a greater chance of finding a match in those possibilities. This is unlike choosing the most constraining variable because the values that we are ordering already satisfy the given constraints: by selecting the most constraining value for the other neighbors, it only limits the trees that one can make and reduces the chances of finding a solution because there are less branches to search. It is important to note that we are not saying that more branches is better, because this is untrue, as shown in choosing the most constrained variables first. Instead, we are saying that in the given constraints, it is best to select values that allow us to search more items, since in that moment there is no knowledge of which branch is better. Thus, since the probability of finding a solution for a branch is almost equal to every other branch, it is best that we allow ourselves the freedom to consider more branches first.\\\\
    Thus, by choosing the most constrained variable and the least constraining value, we avoid pointless searches and search more branches earlier in time, allowing us to find solutions faster.
    
    
\end{homeworkProblem}
\pagebreak
%Part 7%
\begin{homeworkProblem}
    \textbf{\large Consider the following game tree, where the first move is made by the MAX player and the second move is made by the MIN player.}\\\\

   
    \part 

    \textbf{\large What is the best move for the MAX player using the minimax procedure?}\\\\
        The MAX player here has two moves, to go to state B (we'll call this action $a_1$) or go to state C ($a_2$). 
        If MAX chooses $a_1$, then MAX will end with a utility of 3. If MAX choose $a_2$, it ends with a utility of 4 as the game progresses towards state H. 
        We can check this result directly using the definition of the MINIMAX function:
        \begin{align*}
            MINIMAX(root) &= max(min(3,5), min(max(min(0,7), 5), max(7,8), 4)) \\
            &= max(3, min(5,8,4)) \\
            &= max(3,4) = 4
        \end{align*} \\
    \part 

    \textbf{\large Perform a left-to-right (left branch first, then right branch) alpha-beta pruning on the tree. That is, draw only the parts of the tree that are visited and don't draw branches that are cut off (no need to show the alpha or beta values).}\\\\
        \includegraphics*[scale=0.2]{lefttoright.png} \\\\


    \part 

    \textbf{\large Do the same thing as in the previous question, but with a right-to-left ordering of the actions. Discuss why different pruning occurs.} \\\\
        \includegraphics*[scale=0.2]{righttoleft.png} \\
    The differences in pruning arise because we are visiting the nodes in a different order. When going from left to right, the left node is checked with other states
    to see if pruning is a possibility, and if so, the right subtree is pruned. Conversely, going from right to left means that the right node is checked first and left subtrees are pruned.
    This difference in order is what changes the result. For example, when pruning left to right, we visited node K before node L. Seeing as the utility of node K was 7, we pruned off the right subtree of G 
    (as the MIN player would rather go to node F regardless of what node K was). Similarly, when going from right to left, the left subtree of G was pruned (as the MIN player would have opted for node H). 


\end{homeworkProblem}
\pagebreak 

%Part 8%
\begin{homeworkProblem}
\textbf{\large Which of the following are admissible, given admissible heuristics $h_1, h_2$? Which of the following
are consistent, given consistent heuristics $h_1, h_2$? Justify your ans}

\part 

\large $h(n) = min(h_1(n), h_2(n))$\\\\

\part 

\large $h(n) = \omega h_1(n) + (1-\omega)h_2(n)$, where $0 \le \omega \le 1$.\\\\


\part

\large $h(n) = max(h_1(n), h_2(n))$\\\\


\part

\large Which of these heuristics, a, b, or c, would you choose?

\end{homeworkProblem}
\pagebreak
%Part 9%
\begin{homeworkProblem}
    \textbf{\large Simulated annealing is an extension of hill climbing, which uses randomness to avoid getting stuck
    in local maxima and plateaux.}

    \part 
    \large For what types of problems will hill climbing work better than simulated annealing? In other words, when is the
    random part of simulated annealing not necessary?\\\\
    

    \part 

    \large For what types of problems will randomly guessing the state work just as well as simulated annealing? In other
    words, when is the hill-climbing part of simulated annealing not necessary?\\\\


    \part 

    \large Reasoning from your answers to parts (a) and (b) above, for what types of problems is simulated annealing a useful
    technique? In other terms, what assumptions about the shape of the value function are implicit in the design of
    simulated annealing?\\\\

    \part 

    \large As defined in your textbook, simulated annealing returns the current state when the end of the annealing schedule is
    reached and if the annealing schedule is slow enough. Given that we know the value (measure of goodness) of each
    state we visit, is there anything smarter we could do?\\\\

    \part 

    \large Simulated annealing requires a very small amount of memory, just enough to store two states: the current state and
    the proposed next state. Suppose we had enough memory to hold two million states. Propose a modification to
    simulated annealing that makes productive use of the additional memory. In particular, suggest something that will
    likely perform better than just running simulated annealing a million times consecutively with random restarts. [Note:
    There are multiple correct answers here.]\\\\
    
    \part
    
    \large Gradient ascent search is prone to local optima just like hill climbing. Describe how you might adapt randomness in
    simulated annealing to gradient ascent search avoid trap of local maximum.\\\\


    

    
\end{homeworkProblem}



\end{document}
